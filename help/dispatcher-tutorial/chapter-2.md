---
title: 第2章——定义事件内容片段模型
seo-title: AEM内容服务入门——第2章——定义事件内容片段模型
description: AEM无头教程的第2章介绍了如何启用和定义内容片段模型，这些模型用于定义用于创建事件的标准化数据结构和创作界面。
seo-description: AEM无头教程的第2章介绍了如何启用和定义内容片段模型，这些模型用于定义用于创建事件的标准化数据结构和创作界面。
translation-type: tm+mt
source-git-commit: e99779b5d42bb9a3b258e2bbe815defde9d40bf7
workflow-type: tm+mt
source-wordcount: '1917'
ht-degree: 0%

---


# 第2章——基础设施

## 设置缓存基础结构

在本系列第1章中，我们介绍了发布系统和调度程序的基本拓扑。 可以根据预期负载、数据中心的拓扑和所需的故障转移属性，以多种不同的方式配置一组发布和调度程序服务器。

我们将描绘最常见的拓扑，并描述其优势和不足之处。 列表——当然——永远不可能是全面的。 唯一的限制是你的想象力。

### “旧版”设置

在早期，潜在访客的数量很少，硬件很昂贵，Web服务器不像现在这样被视为业务关键。 通常的设置是在两个或多个发布系统之前让一个调度程序充当负载平衡器和缓存。 Dispatcher核心的Apache服务器非常稳定，并且在大多数情况下能够提供相当数量的请求。

![“传统”调度程序设置——按照当今的标准，不太常见](assets/chapter-2/legacy-dispatcher-setup.png)

*“传统”调度程序设置——按照当今的标准，不太常见*

<br> 

这是调度程序从以下位置收到其名称的位置：它基本上在发出请求。 此设置不再很常见，因为它无法满足当今对性能和稳定性的更高要求。

### 多腿设置

现在，稍微不同的拓扑更常见。 多条腿的拓扑每个发布服务器将有一个调度程序。 AEM基础架构前面有专用（硬件）负载平衡器，它将请求调度到以下两条（或多条）腿：

![现代“标准”调度程序设置——易于处理和维护](assets/chapter-2/modern-standard-dispatcher-setup.png)

*现代“标准”调度程序设置——易于处理和维护*

<br> 

这种设置的原因，

1. 网站平均提供的流量比过去多得多。 因此，有必要扩大“阿帕奇基础设施”。

2. “旧版”设置未在调度程序级别提供冗余。 如果Apache Server崩溃，则整个网站都是不可到达的。

3. Apache Server很便宜。 它们基于开放源，并且，如果您有虚拟数据中心，可以非常快地进行配置。

4. 此设置为“滚动”或“交错”更新方案提供了一种简单的方法。 在发布1上安装新软件包时，您只需关闭Dispatcher 1。 安装完成后，并且已经从内部网络对Publish 1进行了充分的烟雾测试，您可以清理Dispatcher 1上的缓存，并重新开始它，同时关闭Dispatcher 2以维护Publish 2。

5. 在此设置中，缓存失效变得非常容易且是确定的。 由于只有一个发布系统连接到一个调度程序，因此只有一个调度程序要失效。 失效的顺序和时间无关紧要。

### “缩小”设置

Apache Server价格低廉，易于配置，为什么不进一步扩展该级别。 为什么每个发布服务器前面没有两个或更多调度程序？

![“扩展”设置——有些应用程序领域，但也有限制和警告](assets/chapter-2/scale-out-setup.png)

*“扩展”设置——有些应用程序领域，但也有限制和警告*

<br> 

你绝对能做到！ 该设置有许多有效的应用程序方案。 但您也应该考虑一些限制和复杂性。

#### 失效

每个发布系统都连接到多个调度程序，每个调度程序在内容发生更改时必须失效。

#### 维护

不言而喻，调度程序和发布系统的初始配置要复杂一些。 但同时要记住，“滚动”版本的工作量也要高一些。 运行时，AEM系统可以且必须更新。 但明智的做法是，在它们积极提供请求的同时不这样做。 通常，您只想更新发布系统的一部分，而其他系统仍在主动提供流量，然后在测试后切换到另一部分。 如果您很幸运，并且可以在部署过程中访问负载平衡器，则可以在此处禁用对维护中服务器的路由。 如果您使用的是共享负载平衡器，但没有直接访问权限，则宁可关闭要更新的发布的调度程序。 越多，你就越要关门。 如果有大量用户并且您计划频繁进行更新，建议您实现一些自动化。 如果您没有自动化工具，扩展仍然是个坏主意。

在过去的项目中，我们使用不同的技巧从负载平衡中删除发布系统，而无需直接访问负载平衡器本身。

负载平衡器通常为“ping”，这是一个特定页面，用于查看服务器是否已启动并正在运行。 通常，ping主页是一个微不足道的选择。 但是，如果要使用ping信号指示负载平衡器不平衡流量，您应选择其他方法。 可创建专用模板或servlet，该模板或servlet可配置为以`"up"`或`"down"`（在正文中或作为http响应代码）进行响应。 当然，该页面的响应不能缓存在调度程序中——因此始终从Publish系统中新获取。 现在，如果配置负载平衡器以检查此模板或servlet，您可以轻松让“发布”“假装”它关闭。 它将不是负载平衡的一部分，并且可以更新。

#### 全球分发

“全球分发”是一个“横向扩展”设置，您在每个发布系统前都有多个调度程序——现在遍布全球，以便更贴近客户并提供更好的性能。 当然，在这种情况下，您没有中央负载平衡器，而是基于DNS和地理IP的负载平衡方案。

>[!NOTE]
>
>实际上，您正在使用此方法构建某种内容分发网络(CDN)-因此您应考虑购买现成的CDN解决方案，而不是自己构建。 构建和维护自定义CDN并非易事任务。

#### 水平缩放

即使在本地数据中心中，“向外扩展”拓扑也具有一些优势，其中每个Publish系统前面有多个调度程序。 如果您发现Apache服务器上由于流量大（以及良好的缓存命中率）而出现性能瓶颈，并且无法再扩展硬件（通过添加CPU、RAM和更快的磁盘），则可以通过添加调度程序来提高性能。 这称为“水平缩放”。 但是，这是有限的，尤其是当您经常使流量失效时。 我们将在下一节中描述其效果。

#### 扩展拓扑的限制

添加代理服务器通常应提高性能。 但是，有些情况下添加服务器实际上会降低性能。 怎么？ 假设您有一个新闻门户，每分钟都可在此介绍新文章和页面。 调度程序因“自动失效”而失效：每当发布页面时，同一站点上缓存中的所有页面都将失效。 这是一个有用的功能——我们在此系列的[第1章](chapter-1.md)中对此进行了介绍——但也意味着，当您的网站频繁发生更改时，缓存会很频繁失效。 如果每个Publish实例只有一个调度程序，则请求页面的第一个访客会触发该页面的重新缓存。 第二个访客已获取缓存版本。

如果您有两个调度程序，则第二个访客有50%的机会未缓存页面，而且当再次呈现该页面时，他会遇到更大的延迟。 每个Publish拥有更多调度程序会使情况更糟。 结果是，发布服务器接收了更多负载，因为它必须分别为每个调度程序重新呈现页面。

![在频繁缓存刷新的缩小场景中性能降低。](assets/chapter-2/decreased-performance.png)

*在频繁缓存刷新的缩小场景中性能降低。*

<br> 

#### 减轻过度扩展问题

您可以考虑为所有调度程序使用中央共享存储，或同步Apache服务器的文件系统以减轻问题。 我们只能提供有限的第一手经验，但要做好准备，这会增加系统的复杂性，并引入全新的错误类别。

我们已经对NFS进行了一些实验，但NFS由于内容锁定而引入了巨大的性能问题。 这实际上降低了整体性能。

**结论** -建议在多个调度程序之间共享一个通用文件系统。

如果您遇到性能问题，请同等地扩展Publish和Dispatcher，以避免Publisher实例的峰值负载。 发布／调度程序比率没有黄金规则——它高度取决于请求的分发以及发布频率和缓存失效。

如果您还担心访客体验的延迟，请考虑使用内容投放网络、缓存重取、抢占式缓存预热、设置宽限时间（如本系列的[第1章](chapter-1.md)所述），或参考[第3部分](chapter-3.md)的一些高级思想。

### “交叉连接”设置

我们时不时会看到的另一个设置是“交叉连接”设置：Publish实例没有专用的调度程序，但所有调度程序都连接到所有Publish系统。

![交叉连接的拓扑：增加冗余和更复杂](assets/chapter-2/cross-connected-setup.png)

<br> 

*交叉连接的拓扑：增加冗余和更复杂。*

乍一看，这为相对较小的预算提供了一些更多冗余。 当其中一台Apache服务器关闭时，您仍可以有两个Publish系统执行渲染工作。 此外，如果某个发布系统崩溃，您仍有两个Dispatcher为缓存负载提供服务。

但这是有代价的。

首先，取一条腿进行维修相当麻烦。 事实上，这就是这个方案的设计目的；以便能够更有弹性，并且能够全力保持运转。 我们看到了如何处理这些问题的复杂维护计划。 首先重新配置Dispatcher 2，删除交叉连接。 正在重新启动Dispatcher 2。 正在关闭Dispatcher 1、更新Publish 1...等等。 如果它长到两条以上，你应该仔细考虑。 你会得出这样的结论：它实际上增加了复杂性，增加了成本，是人类错误的一个可怕来源。 最好自动化这个。 因此，最好检查您是否真的拥有将此自动化任务纳入项目计划的人力资源。 虽然您可以通过此节省一些硬件成本，但您可能会将多次花在IT员工身上。

其次，您可能在AEM上运行一些需要登录的用户应用程序。 您使用粘性会话，以确保始终从同一AEM实例提供一个用户，以便您能够在该实例上保持会话状态。 通过此交叉连接设置，您必须确保在负载平衡器和调度程序上粘性会话正常工作。 这并非不可能，但您需要意识到这一点，并添加一些额外的配置和测试时间，这可能会节省您通过保存硬件计划的成本。

### 结论

我们不建议您将此交叉连接方案用作默认选项。 但是，如果您决定使用它，您将需要仔细评估风险和隐藏成本，并计划将配置自动化纳入您的项目。

## 下一步

* [3 —— 高级缓存主题](chapter-3.md)
